{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/start/.local/share/virtualenvs/DiffuseVAE-vhO6Babt/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**\n",
    "\n",
    "The presented code is not optimized, it serves an educational purpose. It is written for CPU, it uses only fully-connected networks and an extremely simplistic dataset. However, it contains all components that can help to understand how a Variational Auto-Encoder (VAE) works, and it should be rather easy to extend it to more sophisticated models. This code could be run almost on any laptop/PC, and it takes a couple of minutes top to get the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we go wild and use a dataset that is simpler than MNIST! We use a scipy dataset called Digits. It consists of ~1500 images of size 8x8, and each pixel can take values in $\\{0, 1, \\ldots, 16\\}$.\n",
    "\n",
    "The goal of using this dataset is that everyone can run it on a laptop, without any gpu etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the blogpost for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.e-5\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1. - EPS)\n",
    "    log_p = x * torch.log(pp) + (1. - x) * torch.log(1. - pp)\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_standard_normal(x, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_net):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # The init of the encoder network.\n",
    "        self.encoder = encoder_net\n",
    "\n",
    "    # The reparameterization trick for Gaussians.\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        # The formula is the following:\n",
    "        # z = mu + std * epsilon\n",
    "        # epsilon ~ Normal(0,1)\n",
    "        \n",
    "        # 1st, we need to get std from log-variance.\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        \n",
    "        # 2nd, we sample epsilon from Normal(0,1).\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        # The final output.\n",
    "        return mu + std * eps\n",
    "    \n",
    "    # This function implements the output of the encoder network (i.e., parameters of a Gaussian).\n",
    "    def encode(self, x):\n",
    "        # 1st, we calculate the output of the encoder network of size 2M.\n",
    "        h_e = self.encoder(x)\n",
    "        # 2nd, we must divide the output into the mean and the log-variance.\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
    "\n",
    "        return mu_e, log_var_e\n",
    "    \n",
    "    # Sampling procedure\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        # If we don't provide a mean and a log-variance, we must first calculate it.\n",
    "        if (mu_e is None) and (log_var_e is None):\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "        else:\n",
    "            if (mu_e is None) or (log_var_e is None):\n",
    "                raise ValueError('mu and log-var can`t be None!')\n",
    "        # Otherwise, we can simply apply the reparametrization trick.\n",
    "        z = self.reparameterization(mu_e, log_var_e)\n",
    "        return z\n",
    "\n",
    "    # This function calculates the log-probability that is later used for calculating the ELBO.\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        # If we provide x alone, then we can calculate a corresponding sample:\n",
    "        if x is not None:\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        else:\n",
    "        # Otherwise, we should provide mu, log-var, and z.\n",
    "            if (mu_e is None) or (log_var_e is None) or (z is None):\n",
    "                raise ValueError('mu, log-var and z can`t be None!')\n",
    "\n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "\n",
    "    # PyTorch forward pass: it's ither log-probability (by default) or sampling.\n",
    "    def forward(self, x, type='log_prob'):\n",
    "        assert type in ['encode', 'log_prob'], 'Type could be either encode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_net, distribution='categorical', num_vals=None):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # The decoder network.\n",
    "        self.decoder = decoder_net\n",
    "        # The distribution used for the decoder.\n",
    "        self.distribution = distribution\n",
    "        # The number of possible values. This is important for the categorical distribution.\n",
    "        self.num_vals=num_vals\n",
    "\n",
    "    # This function calculates parameters of the likelihood function p(x|z)\n",
    "    def decode(self, z):\n",
    "        # 1st, we apply the decoder network.\n",
    "        h_d = self.decoder(z)\n",
    "        \n",
    "        if self.distribution == 'categorical':\n",
    "            # We save the shapes: batch size\n",
    "            b = h_d.shape[0]\n",
    "            # and the dimensionality of x.\n",
    "            d = h_d.shape[1]//self.num_vals\n",
    "            # Then we reshape to (Batch size, Dimensionality, Number of Values).\n",
    "            h_d = h_d.view(b, d, self.num_vals)\n",
    "            # To get probabilities, we apply softmax.\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "            return [mu_d]\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            # In the Bernoulli case, we have x_d \\in {0,1}. Therefore, it's enough to output a single probability, because p(x_d=1|z) = \\theta, and p(x_d=0|z) = 1-\\theta\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            return [mu_d]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Either `categorical` or `bernoulli`')\n",
    "\n",
    "    def sample(self, z):\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == 'categorical':\n",
    "            # We take the output of the decoder\n",
    "            mu_d = outs[0]\n",
    "            # and save shapes (we'll need that for reshaping).\n",
    "            b = mu_d.shape[0]\n",
    "            m = mu_d.shape[1]\n",
    "            # Here we use reshaping.\n",
    "            mu_d = mu_d.view(mu_d.shape[0], -1, self.num_vals)\n",
    "            p = mu_d.view(-1, self.num_vals)\n",
    "            # Eventually, we sample from the categorical\n",
    "            x_new = torch.multinomial(p, num_samples=1).view(b, m)\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = outs[0]\n",
    "            x_new = torch.bernoulli(mu_d)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Either `categorical` or `bernoulli`')\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def log_prob(self, x, z):\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == 'categorical':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "            \n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_bernoulli(x, mu_d, reduction='sum', dim=-1)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('Either `categorical` or `bernoulli`')\n",
    "\n",
    "        return log_p\n",
    "\n",
    "    def forward(self, z, x=None, type='log_prob'):\n",
    "        assert type in ['decoder', 'log_prob'], 'Type could be either decode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x, z)\n",
    "        else:\n",
    "            return self.sample(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prior**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We could have used a built-in PyTorch distribution. However, we didn't do that for 2 reasons:\n",
    "(1) It's important to think of the prior as a crucial component in VAEs.\n",
    "(2) We can implement a learnable prior (e.g., a flow-based prior, VampPrior, a mixture of distributions.)\n",
    "\"\"\"\n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(Prior, self).__init__()\n",
    "        self.L = L\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        z = torch.randn((batch_size, self.L))\n",
    "        return z\n",
    "\n",
    "    def log_prob(self, z):\n",
    "        return log_standard_normal(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net, num_vals=256, L=16, likelihood_type='categorical'):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        print('VAE by JT.')\n",
    "\n",
    "        self.encoder = Encoder(encoder_net=encoder_net)\n",
    "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net, num_vals=num_vals)\n",
    "        self.prior = Prior(L=L)\n",
    "\n",
    "        self.num_vals = num_vals\n",
    "\n",
    "        self.likelihood_type = likelihood_type\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        # encoder\n",
    "        mu_e, log_var_e = self.encoder.encode(x)\n",
    "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "\n",
    "        # ELBO\n",
    "        RE = self.decoder.log_prob(x, z)\n",
    "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            return -(RE + KL).sum()\n",
    "        else:\n",
    "            return -(RE + KL).mean()\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions: training, evaluation, plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's rather self-explanatory, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=''):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            if hasattr(model, 'dequantization'):\n",
    "                if model.dequantization:\n",
    "                    batch = batch + torch.rand(batch.shape)\n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "result_dir = 'results/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'vae'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64   # input dimension\n",
    "L = 16  # number of latents\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE by JT.\n",
      "ENCODER:\n",
      " -----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1            [1, 256]          16,640          16,640\n",
      "       LeakyReLU-2            [1, 256]               0               0\n",
      "          Linear-3            [1, 256]          65,792          65,792\n",
      "       LeakyReLU-4            [1, 256]               0               0\n",
      "          Linear-5             [1, 32]           8,224           8,224\n",
      "=======================================================================\n",
      "Total params: 90,656\n",
      "Trainable params: 90,656\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "DECODER:\n",
      " -----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1            [1, 256]           4,352           4,352\n",
      "       LeakyReLU-2            [1, 256]               0               0\n",
      "          Linear-3            [1, 256]          65,792          65,792\n",
      "       LeakyReLU-4            [1, 256]               0               0\n",
      "          Linear-5           [1, 1088]         279,616         279,616\n",
      "=======================================================================\n",
      "Total params: 349,760\n",
      "Trainable params: 349,760\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "likelihood_type = 'categorical'\n",
    "\n",
    "if likelihood_type == 'categorical':\n",
    "    num_vals = 17\n",
    "elif likelihood_type == 'bernoulli':\n",
    "    num_vals = 1\n",
    "\n",
    "# Remember that the encoder outputs 2x more values because we need L means and L log-variances for a Gaussian.\n",
    "encoder = nn.Sequential(nn.Linear(D, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, 2 * L))\n",
    "\n",
    "# Here we must remember that if we use the categorical distribution, we must output num_vals per each pixel.\n",
    "decoder = nn.Sequential(nn.Linear(L, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, num_vals * D))\n",
    "\n",
    "prior = torch.distributions.MultivariateNormal(torch.zeros(L), torch.eye(L))\n",
    "model = VAE(encoder_net=encoder, decoder_net=decoder, num_vals=num_vals, L=L, likelihood_type=likelihood_type)\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(\"ENCODER:\\n\", summary(encoder, torch.zeros(1, D), show_input=False, show_hierarchical=False))\n",
    "print(\"\\nDECODER:\\n\", summary(decoder, torch.zeros(1, L), show_input=False, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play! Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=127.05658621651786\n",
      "saved!\n",
      "Epoch: 1, val nll=113.49946428571428\n",
      "saved!\n",
      "Epoch: 2, val nll=112.30336704799107\n",
      "saved!\n",
      "Epoch: 3, val nll=111.77201102120536\n",
      "saved!\n",
      "Epoch: 4, val nll=111.70485072544643\n",
      "saved!\n",
      "Epoch: 5, val nll=111.59772042410714\n",
      "saved!\n",
      "Epoch: 6, val nll=111.56715122767856\n",
      "saved!\n",
      "Epoch: 7, val nll=111.45921944754464\n",
      "saved!\n",
      "Epoch: 8, val nll=111.35287388392857\n",
      "saved!\n",
      "Epoch: 9, val nll=111.375634765625\n",
      "Epoch: 10, val nll=111.246220703125\n",
      "saved!\n",
      "Epoch: 11, val nll=111.17105398995535\n",
      "saved!\n",
      "Epoch: 12, val nll=111.37622837611607\n",
      "Epoch: 13, val nll=111.26294084821428\n",
      "Epoch: 14, val nll=111.1961865234375\n",
      "Epoch: 15, val nll=110.93104143415178\n",
      "saved!\n",
      "Epoch: 16, val nll=110.48345493861608\n",
      "saved!\n",
      "Epoch: 17, val nll=110.5515283203125\n",
      "Epoch: 18, val nll=110.59109165736608\n",
      "Epoch: 19, val nll=110.017568359375\n",
      "saved!\n",
      "Epoch: 20, val nll=109.99543596540178\n",
      "saved!\n",
      "Epoch: 21, val nll=109.88622698102678\n",
      "saved!\n",
      "Epoch: 22, val nll=109.53420549665178\n",
      "saved!\n",
      "Epoch: 23, val nll=109.4867529296875\n",
      "saved!\n",
      "Epoch: 24, val nll=109.01774762834822\n",
      "saved!\n",
      "Epoch: 25, val nll=109.07068638392857\n",
      "Epoch: 26, val nll=108.70533482142856\n",
      "saved!\n",
      "Epoch: 27, val nll=108.20866838727679\n",
      "saved!\n",
      "Epoch: 28, val nll=108.21834054129464\n",
      "Epoch: 29, val nll=107.54113909040178\n",
      "saved!\n",
      "Epoch: 30, val nll=107.57022321428572\n",
      "Epoch: 31, val nll=107.47082310267857\n",
      "saved!\n",
      "Epoch: 32, val nll=106.98588169642858\n",
      "saved!\n",
      "Epoch: 33, val nll=106.76454659598214\n",
      "saved!\n",
      "Epoch: 34, val nll=106.14520926339286\n",
      "saved!\n",
      "Epoch: 35, val nll=105.73947684151786\n",
      "saved!\n",
      "Epoch: 36, val nll=105.75908830915179\n",
      "Epoch: 37, val nll=104.85349330357143\n",
      "saved!\n",
      "Epoch: 38, val nll=104.88015345982143\n",
      "Epoch: 39, val nll=104.75093889508929\n",
      "saved!\n",
      "Epoch: 40, val nll=104.17380022321429\n",
      "saved!\n",
      "Epoch: 41, val nll=104.26016392299107\n",
      "Epoch: 42, val nll=104.16401018415179\n",
      "saved!\n",
      "Epoch: 43, val nll=103.72773507254465\n",
      "saved!\n",
      "Epoch: 44, val nll=103.49398158482143\n",
      "saved!\n",
      "Epoch: 45, val nll=103.71899832589285\n",
      "Epoch: 46, val nll=103.89102678571429\n",
      "Epoch: 47, val nll=103.69656598772322\n",
      "Epoch: 48, val nll=103.03930036272321\n",
      "saved!\n",
      "Epoch: 49, val nll=102.90252580915178\n",
      "saved!\n",
      "Epoch: 50, val nll=102.79849539620535\n",
      "saved!\n",
      "Epoch: 51, val nll=102.59326171875\n",
      "saved!\n",
      "Epoch: 52, val nll=102.80732073102679\n",
      "Epoch: 53, val nll=102.74109514508929\n",
      "Epoch: 54, val nll=102.25483956473214\n",
      "saved!\n",
      "Epoch: 55, val nll=102.3946435546875\n",
      "Epoch: 56, val nll=102.44886439732143\n",
      "Epoch: 57, val nll=102.10811244419642\n",
      "saved!\n",
      "Epoch: 58, val nll=102.02182198660714\n",
      "saved!\n",
      "Epoch: 59, val nll=101.96008928571429\n",
      "saved!\n",
      "Epoch: 60, val nll=101.87942452566965\n",
      "saved!\n",
      "Epoch: 61, val nll=101.65939801897322\n",
      "saved!\n",
      "Epoch: 62, val nll=101.92310198102679\n",
      "Epoch: 63, val nll=101.47689801897322\n",
      "saved!\n",
      "Epoch: 64, val nll=101.54396414620535\n",
      "Epoch: 65, val nll=101.92120396205357\n",
      "Epoch: 66, val nll=101.49629045758928\n",
      "Epoch: 67, val nll=101.563916015625\n",
      "Epoch: 68, val nll=101.4857958984375\n",
      "Epoch: 69, val nll=101.50094308035715\n",
      "Epoch: 70, val nll=101.35670758928572\n",
      "saved!\n",
      "Epoch: 71, val nll=101.61426199776785\n",
      "Epoch: 72, val nll=101.4181591796875\n",
      "Epoch: 73, val nll=101.24339285714285\n",
      "saved!\n",
      "Epoch: 74, val nll=101.30567243303571\n",
      "Epoch: 75, val nll=101.22649553571429\n",
      "saved!\n",
      "Epoch: 76, val nll=101.07451729910714\n",
      "saved!\n",
      "Epoch: 77, val nll=101.13044294084821\n",
      "Epoch: 78, val nll=100.93921665736607\n",
      "saved!\n",
      "Epoch: 79, val nll=101.17054478236606\n",
      "Epoch: 80, val nll=101.49403529575893\n",
      "Epoch: 81, val nll=101.25447893415179\n",
      "Epoch: 82, val nll=101.13566615513393\n",
      "Epoch: 83, val nll=101.16694754464285\n",
      "Epoch: 84, val nll=101.05693359375\n",
      "Epoch: 85, val nll=101.16655552455357\n",
      "Epoch: 86, val nll=101.1200146484375\n",
      "Epoch: 87, val nll=101.63183523995535\n",
      "Epoch: 88, val nll=100.99574567522322\n",
      "Epoch: 89, val nll=100.88653599330357\n",
      "saved!\n",
      "Epoch: 90, val nll=101.07251953125\n",
      "Epoch: 91, val nll=100.90427734375\n",
      "Epoch: 92, val nll=101.05616908482143\n",
      "Epoch: 93, val nll=101.04021623883929\n",
      "Epoch: 94, val nll=100.70205496651786\n",
      "saved!\n",
      "Epoch: 95, val nll=101.06309221540178\n",
      "Epoch: 96, val nll=100.78490443638393\n",
      "Epoch: 97, val nll=100.93614048549107\n",
      "Epoch: 98, val nll=100.84577845982143\n",
      "Epoch: 99, val nll=100.70893484933036\n",
      "Epoch: 100, val nll=101.00894880022321\n",
      "Epoch: 101, val nll=101.11936872209822\n",
      "Epoch: 102, val nll=100.81837332589286\n",
      "Epoch: 103, val nll=100.86832728794643\n",
      "Epoch: 104, val nll=101.42160784040179\n",
      "Epoch: 105, val nll=101.08190011160714\n",
      "Epoch: 106, val nll=101.13497349330358\n",
      "Epoch: 107, val nll=100.96838936941964\n",
      "Epoch: 108, val nll=100.9525634765625\n",
      "Epoch: 109, val nll=100.80383649553572\n",
      "Epoch: 110, val nll=101.13035086495536\n",
      "Epoch: 111, val nll=100.71309430803572\n",
      "Epoch: 112, val nll=100.99882533482143\n",
      "Epoch: 113, val nll=100.97662458147322\n",
      "Epoch: 114, val nll=101.01736955915179\n",
      "Epoch: 115, val nll=101.47135393415178\n"
     ]
    }
   ],
   "source": [
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=96.75070893631153\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiffuseVAE-vhO6Babt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
